{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import numpy as np \n",
    "import scipy as sp \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from scipy.stats import norm  \n",
    "sns.set_style('white') \n",
    "sns.set_context('talk')  \n",
    "np.random.seed(123)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.special as sp\n",
    "from scipy import integrate\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import anderson\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asy1(estimator, X, y):\n",
    "    Penalty_1 = np.array([[-10,10], [1,0]])\n",
    "    answ = np.int64(estimator.predict(X))\n",
    "    return np.sum(Penalty_1[y, answ])\n",
    "    \n",
    "def asy2(estimator, X, y):\n",
    "    Penalty_2 = np.array([[-1,2], [1,-1]])\n",
    "    answ = np.int64(estimator.predict(X))\n",
    "    return np.sum(Penalty_2[y, answ])\n",
    "\n",
    "def num(estimator, X, y):\n",
    "    answ = np.int64(estimator.predict(X))\n",
    "    return np.sum(np.abs(answ - y) > 0)\n",
    "\n",
    "def _num(y1, y2):\n",
    "    return np.sum(np.abs(y1 - y2) > 0)\n",
    "\n",
    "def _acc(y1, y2):\n",
    "    return np.sum(y1 == y2)\n",
    "\n",
    "def _asy1(y1, y2):\n",
    "    Penalty_1 = np.array([[-10,10], [1,0]])\n",
    "    return np.sum(Penalty_1[y1, y2])\n",
    "\n",
    "def _asy2(y1, y2):\n",
    "    Penalty_2 = np.array([[-1,2], [1,-1]])\n",
    "    return np.sum(Penalty_2[y1, y2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(X, alpha):\n",
    "    num_features = X.shape[1]\n",
    "    q_low = X.quantile(alpha, axis=0)\n",
    "    q_up = X.quantile(1 - alpha, axis=0)\n",
    "    X_new = X.values.copy()\n",
    "    for i in range(num_features):\n",
    "        median = X[i].median()\n",
    "        for j in range(X.shape[0]):\n",
    "            if X_new[j][i] < q_low[i] or X_new[j][i] > q_up[i]:\n",
    "                X_new[j][i] = median\n",
    "    return X_new\n",
    "        \n",
    "    \n",
    "def comp(X, lower, upper):\n",
    "    outliers = []\n",
    "    for i in range(X.shape[0]):\n",
    "        if np.sum(X[i] < lower) + np.sum(X[i] > upper) > 0:\n",
    "            outliers.append(i)\n",
    "    return outliers\n",
    " \n",
    "def check_outliers(X, alpha = 0.25):\n",
    "    q25 = X.quantile(alpha, axis=0)\n",
    "    q75 = X.quantile(1-alpha, axis=0)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.75\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    outliers = comp(X.values, lower, upper)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_load = pd.read_csv('./data/task1_5_learn_X.csv',header=None, sep=' ').as_matrix()\n",
    "y_train_load = np.reshape(np.int64(pd.read_csv('./data/task1_5_learn_y.csv',header=None, sep=' ').as_matrix()), -1)\n",
    "\n",
    "X_test_load = pd.read_csv('./data/task1_5_test_X.csv',header=None, sep=' ').as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>825.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.217510</td>\n",
       "      <td>40.010900</td>\n",
       "      <td>266.641564</td>\n",
       "      <td>151.310718</td>\n",
       "      <td>188.550365</td>\n",
       "      <td>20.668682</td>\n",
       "      <td>246.017131</td>\n",
       "      <td>35.003113</td>\n",
       "      <td>248.643614</td>\n",
       "      <td>40.011008</td>\n",
       "      <td>...</td>\n",
       "      <td>6.570545</td>\n",
       "      <td>121.348152</td>\n",
       "      <td>58.112808</td>\n",
       "      <td>-29.185405</td>\n",
       "      <td>0.690829</td>\n",
       "      <td>-6.591668</td>\n",
       "      <td>270.041628</td>\n",
       "      <td>-292.672099</td>\n",
       "      <td>379.606797</td>\n",
       "      <td>-27.023733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1916.980653</td>\n",
       "      <td>1497.516499</td>\n",
       "      <td>9979.856140</td>\n",
       "      <td>5663.234926</td>\n",
       "      <td>7057.019655</td>\n",
       "      <td>773.590087</td>\n",
       "      <td>9208.037085</td>\n",
       "      <td>1310.098923</td>\n",
       "      <td>9306.213137</td>\n",
       "      <td>1497.505170</td>\n",
       "      <td>...</td>\n",
       "      <td>5446.761379</td>\n",
       "      <td>4382.164948</td>\n",
       "      <td>2091.557347</td>\n",
       "      <td>7545.961821</td>\n",
       "      <td>529.603094</td>\n",
       "      <td>1231.532474</td>\n",
       "      <td>5423.923011</td>\n",
       "      <td>8271.161462</td>\n",
       "      <td>7335.915924</td>\n",
       "      <td>956.598566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6640.748129</td>\n",
       "      <td>-5187.644170</td>\n",
       "      <td>-34571.899053</td>\n",
       "      <td>-19618.408527</td>\n",
       "      <td>-24446.869206</td>\n",
       "      <td>-2679.851205</td>\n",
       "      <td>-31898.337622</td>\n",
       "      <td>-4538.401901</td>\n",
       "      <td>-32238.118667</td>\n",
       "      <td>-5187.603523</td>\n",
       "      <td>...</td>\n",
       "      <td>-16412.742421</td>\n",
       "      <td>-13441.165313</td>\n",
       "      <td>-7216.154021</td>\n",
       "      <td>-26317.493525</td>\n",
       "      <td>-1440.640200</td>\n",
       "      <td>-3737.641531</td>\n",
       "      <td>-16044.440120</td>\n",
       "      <td>-27638.483247</td>\n",
       "      <td>-24054.671596</td>\n",
       "      <td>-2748.341010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1180.119209</td>\n",
       "      <td>-921.901240</td>\n",
       "      <td>-6143.636109</td>\n",
       "      <td>-3486.483723</td>\n",
       "      <td>-4344.388951</td>\n",
       "      <td>-476.228417</td>\n",
       "      <td>-5668.779002</td>\n",
       "      <td>-806.522801</td>\n",
       "      <td>-5729.103624</td>\n",
       "      <td>-921.885820</td>\n",
       "      <td>...</td>\n",
       "      <td>-3462.148238</td>\n",
       "      <td>-2777.027771</td>\n",
       "      <td>-1297.072343</td>\n",
       "      <td>-5273.055435</td>\n",
       "      <td>-358.466169</td>\n",
       "      <td>-864.064167</td>\n",
       "      <td>-3303.140474</td>\n",
       "      <td>-6032.867444</td>\n",
       "      <td>-4643.568352</td>\n",
       "      <td>-639.110908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-11.806047</td>\n",
       "      <td>-9.199941</td>\n",
       "      <td>-61.504062</td>\n",
       "      <td>-34.846866</td>\n",
       "      <td>-43.687624</td>\n",
       "      <td>-4.776866</td>\n",
       "      <td>-56.750160</td>\n",
       "      <td>-8.052006</td>\n",
       "      <td>-57.325787</td>\n",
       "      <td>-9.210766</td>\n",
       "      <td>...</td>\n",
       "      <td>173.832986</td>\n",
       "      <td>130.435697</td>\n",
       "      <td>16.350993</td>\n",
       "      <td>-50.957639</td>\n",
       "      <td>-21.609337</td>\n",
       "      <td>-27.487198</td>\n",
       "      <td>62.914775</td>\n",
       "      <td>-175.174578</td>\n",
       "      <td>491.955592</td>\n",
       "      <td>-74.822854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1452.603755</td>\n",
       "      <td>1134.732730</td>\n",
       "      <td>7562.363326</td>\n",
       "      <td>4291.294985</td>\n",
       "      <td>5347.571160</td>\n",
       "      <td>586.194835</td>\n",
       "      <td>6977.655975</td>\n",
       "      <td>992.735002</td>\n",
       "      <td>7051.809507</td>\n",
       "      <td>1134.740120</td>\n",
       "      <td>...</td>\n",
       "      <td>3530.812431</td>\n",
       "      <td>3112.717474</td>\n",
       "      <td>1490.956269</td>\n",
       "      <td>5234.042278</td>\n",
       "      <td>364.798303</td>\n",
       "      <td>817.081198</td>\n",
       "      <td>4081.902732</td>\n",
       "      <td>5759.704247</td>\n",
       "      <td>5687.515246</td>\n",
       "      <td>633.657897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5637.328736</td>\n",
       "      <td>4403.785574</td>\n",
       "      <td>29348.110905</td>\n",
       "      <td>16654.108107</td>\n",
       "      <td>20752.854650</td>\n",
       "      <td>2274.923828</td>\n",
       "      <td>27078.324382</td>\n",
       "      <td>3852.654052</td>\n",
       "      <td>27366.986911</td>\n",
       "      <td>4403.755830</td>\n",
       "      <td>...</td>\n",
       "      <td>18302.328234</td>\n",
       "      <td>12276.952334</td>\n",
       "      <td>6434.242120</td>\n",
       "      <td>25490.401150</td>\n",
       "      <td>1703.633296</td>\n",
       "      <td>4308.371014</td>\n",
       "      <td>14656.687160</td>\n",
       "      <td>20549.919473</td>\n",
       "      <td>22916.561208</td>\n",
       "      <td>3339.002276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1             2             3             4   \\\n",
       "count   825.000000   825.000000    825.000000    825.000000    825.000000   \n",
       "mean     51.217510    40.010900    266.641564    151.310718    188.550365   \n",
       "std    1916.980653  1497.516499   9979.856140   5663.234926   7057.019655   \n",
       "min   -6640.748129 -5187.644170 -34571.899053 -19618.408527 -24446.869206   \n",
       "25%   -1180.119209  -921.901240  -6143.636109  -3486.483723  -4344.388951   \n",
       "50%     -11.806047    -9.199941    -61.504062    -34.846866    -43.687624   \n",
       "75%    1452.603755  1134.732730   7562.363326   4291.294985   5347.571160   \n",
       "max    5637.328736  4403.785574  29348.110905  16654.108107  20752.854650   \n",
       "\n",
       "                5             6            7             8            9   \\\n",
       "count   825.000000    825.000000   825.000000    825.000000   825.000000   \n",
       "mean     20.668682    246.017131    35.003113    248.643614    40.011008   \n",
       "std     773.590087   9208.037085  1310.098923   9306.213137  1497.505170   \n",
       "min   -2679.851205 -31898.337622 -4538.401901 -32238.118667 -5187.603523   \n",
       "25%    -476.228417  -5668.779002  -806.522801  -5729.103624  -921.885820   \n",
       "50%      -4.776866    -56.750160    -8.052006    -57.325787    -9.210766   \n",
       "75%     586.194835   6977.655975   992.735002   7051.809507  1134.740120   \n",
       "max    2274.923828  27078.324382  3852.654052  27366.986911  4403.755830   \n",
       "\n",
       "          ...                 40            41           42            43  \\\n",
       "count     ...         825.000000    825.000000   825.000000    825.000000   \n",
       "mean      ...           6.570545    121.348152    58.112808    -29.185405   \n",
       "std       ...        5446.761379   4382.164948  2091.557347   7545.961821   \n",
       "min       ...      -16412.742421 -13441.165313 -7216.154021 -26317.493525   \n",
       "25%       ...       -3462.148238  -2777.027771 -1297.072343  -5273.055435   \n",
       "50%       ...         173.832986    130.435697    16.350993    -50.957639   \n",
       "75%       ...        3530.812431   3112.717474  1490.956269   5234.042278   \n",
       "max       ...       18302.328234  12276.952334  6434.242120  25490.401150   \n",
       "\n",
       "                44           45            46            47            48  \\\n",
       "count   825.000000   825.000000    825.000000    825.000000    825.000000   \n",
       "mean      0.690829    -6.591668    270.041628   -292.672099    379.606797   \n",
       "std     529.603094  1231.532474   5423.923011   8271.161462   7335.915924   \n",
       "min   -1440.640200 -3737.641531 -16044.440120 -27638.483247 -24054.671596   \n",
       "25%    -358.466169  -864.064167  -3303.140474  -6032.867444  -4643.568352   \n",
       "50%     -21.609337   -27.487198     62.914775   -175.174578    491.955592   \n",
       "75%     364.798303   817.081198   4081.902732   5759.704247   5687.515246   \n",
       "max    1703.633296  4308.371014  14656.687160  20549.919473  22916.561208   \n",
       "\n",
       "                49  \n",
       "count   825.000000  \n",
       "mean    -27.023733  \n",
       "std     956.598566  \n",
       "min   -2748.341010  \n",
       "25%    -639.110908  \n",
       "50%     -74.822854  \n",
       "75%     633.657897  \n",
       "max    3339.002276  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_load[np.where(y_train_load==0)]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 50)\n",
      "(1000,)\n",
      "(10000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_load.shape)\n",
    "print(y_train_load.shape)\n",
    "print(X_test_load.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_load = replace_outliers(pd.DataFrame(X_train_load), 0.0141)\n",
    "# X_test_load = replace_outliers(pd.DataFrame(X_test_load), 0.0141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=1, score_func=<function mutual_info_classif at 0x1144b7b70>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skb = SelectKBest(f_classif, k=1)\n",
    "skb = SelectKBest(mutual_info_classif, k=1)\n",
    "skb.fit(X_train_load, y_train_load)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1152d7e80>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107f476a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sort(skb.scores_)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01671327,  0.01355971,  0.0083354 ,  0.00705872,  0.00162274,\n",
       "        0.00162274,  0.00158826,  0.00158826,  0.00152828,  0.00147967,\n",
       "        0.00144242,  0.00122967,  0.00111881,  0.00078548,  0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(skb.scores_)[::-1][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "skb.k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = skb.transform(scale(np.vstack([X_train_load, X_test_load])))\n",
    "# X = skb.transform(np.vstack([X_train_load, X_test_load]))\n",
    "# X = (X - np.mean(X, axis=0))/np.std(X, axis=0)\n",
    "\n",
    "X_train = X[:X_train_load.shape[0]]\n",
    "X_test = X[X_train_load.shape[0]:]\n",
    "\n",
    "y_train = np.array(y_train_load)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8250 -1000\n",
      "175\n"
     ]
    }
   ],
   "source": [
    "print(_asy1(y_train, y_train), _asy2(y_train, y_train))\n",
    "print(np.sum(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,8))\n",
    "# sns.heatmap(pd.DataFrame(X_train).corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_features = [0, 10, 20, 30, 40, 41,42,43,44,45,46,47,48,49]\n",
    "# saved_features = [0, 10, 11, 12, 13]\n",
    "X_train = X_train[:,saved_features]\n",
    "X_test = X_test[:,saved_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,8))\n",
    "# sns.heatmap(pd.DataFrame(X_train).corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 14)\n",
      "(1000,)\n",
      "(10000, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, y_train_new = SMOTE().fit_sample(X_train, y_train)\n",
    "X_test_new = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 14) (10000, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_new.shape, X_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8250 -1650\n",
      "825\n"
     ]
    }
   ],
   "source": [
    "print(_asy1(y_train_new, y_train_new), _asy2(y_train_new, y_train_new))\n",
    "print(np.sum(y_train_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.816363636364\n",
      "AUC 0.888959412305\n",
      "NUM 303\n",
      "ASY1 -4774\n",
      "ASY2 -877\n"
     ]
    }
   ],
   "source": [
    "rho = 0.5\n",
    "Predict = cross_val_predict(estimator=svm.SVC(probability=True, kernel='rbf'), X=X_train_new, y=y_train_new, cv = 10, method='predict_proba')\n",
    "\n",
    "\n",
    "print('ACC', metrics.accuracy_score(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "print('AUC', metrics.roc_auc_score(y_train_new, Predict[:,1]))\n",
    "print('NUM', _num(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "print('ASY1', _asy1(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "print('ASY2', _asy2(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "\n",
    "Predict_For_AUC = svm.SVC(probability=True, kernel='rbf').fit(X_train_new, y_train_new).predict(X_test_new)\n",
    "Predict_For_NUM = svm.SVC(probability=True, kernel='rbf').fit(X_train_new, y_train_new).predict(X_test_new)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.573939393939\n",
      "AUC 0.890267768595\n",
      "NUM 703\n",
      "ASY1 -7319\n",
      "ASY2 -232\n"
     ]
    }
   ],
   "source": [
    "rho = 0.9\n",
    "Predict = cross_val_predict(estimator=svm.SVC(probability=True, kernel='rbf'), X=X_train_new, y=y_train_new, cv = 10, method='predict_proba')\n",
    "\n",
    "\n",
    "print('ACC', metrics.accuracy_score(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "print('AUC', metrics.roc_auc_score(y_train_new, Predict[:,1]))\n",
    "print('NUM', _num(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "print('ASY1', _asy1(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "print('ASY2', _asy2(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "\n",
    "Predict_For_ASY1 = svm.SVC(probability=True, kernel='rbf').fit(X_train_new, y_train_new).predict(X_test_new)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.816363636364\n",
      "AUC 0.889995224977\n",
      "NUM 303\n",
      "ASY1 -6237\n",
      "ASY2 -954\n"
     ]
    }
   ],
   "source": [
    "rho = 0.66\n",
    "Predict = cross_val_predict(estimator=svm.SVC(probability=True, kernel='rbf'), X=X_train_new, y=y_train_new, cv = 10, method='predict_proba')\n",
    "\n",
    "\n",
    "print('ACC', metrics.accuracy_score(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "print('AUC', metrics.roc_auc_score(y_train_new, Predict[:,1]))\n",
    "print('NUM', _num(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "print('ASY1', _asy1(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "print('ASY2', _asy2(y_train_new, np.int64(Predict[:,1]>rho)))\n",
    "\n",
    "Predict_For_ASY2 = svm.SVC(probability=True, kernel='rbf').fit(X_train_new, y_train_new).predict(X_test_new)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.vstack([Predict_For_AUC, Predict_For_NUM, Predict_For_ASY1, Predict_For_ASY2]).T).to_csv('task1_5_answ.csv', sep = ',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
