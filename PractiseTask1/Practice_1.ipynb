{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy as sp \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm  \n",
    "np.random.seed(123)\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scipy.special as sp\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import anderson\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3, 5, 7, 9, 10, 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bad_data(Data):\n",
    "    Data_list = []\n",
    "    for string in Data:\n",
    "        Data_list.append(np.array([float(i) for i in str(string[0]).split()]))\n",
    "    \n",
    "    return np.array(Data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plot_importance(booster, figsize, **kwargs):\n",
    "    from xgboost import plot_importance\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    return plot_importance(booster=booster, ax=ax, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asy1(estimator, X, y):\n",
    "    Penalty_1 = np.array([[-10,10], [1,0]])\n",
    "    answ = np.int64(estimator.predict(X))\n",
    "    return np.sum(Penalty_1[y, answ])\n",
    "    \n",
    "def asy2(estimator, X, y):\n",
    "    Penalty_2 = np.array([[-1,2], [1,-1]])\n",
    "    answ = np.int64(estimator.predict(X))\n",
    "    return np.sum(Penalty_2[y, answ])\n",
    "\n",
    "def num(estimator, X, y):\n",
    "    answ = np.int64(estimator.predict(X))\n",
    "    return np.sum(np.abs(answ - y) > 0)\n",
    "\n",
    "def _num(y1, y2):\n",
    "    return np.sum(np.abs(y1 - y2) > 0)\n",
    "\n",
    "def _acc(y1, y2):\n",
    "    return np.sum(y1 == y2)\n",
    "\n",
    "def _asy1(y1, y2):\n",
    "    Penalty_1 = np.array([[-10,10], [1,0]])\n",
    "    return np.sum(Penalty_1[y1, y2])\n",
    "\n",
    "def _asy2(y1, y2):\n",
    "    Penalty_2 = np.array([[-1,2], [1,-1]])\n",
    "    return np.sum(Penalty_2[y1, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp(X, lower, upper):\n",
    "    outliers = []\n",
    "    for i in range(X.shape[0]):\n",
    "        if np.sum(X[i] < lower) + np.sum(X[i] > upper) > 0:\n",
    "            outliers.append(i)\n",
    "    return outliers\n",
    " \n",
    "def check_outliers(X):\n",
    "    q25 = X.quantile(0.25, axis=0)\n",
    "    q75 = X.quantile(0.75, axis=0)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.75\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    outliers = comp(X.values, lower, upper)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset № 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = convert_bad_data(pd.read_csv('./data/task1_13_learn_X.csv').values)\n",
    "#y_train = np.int64(np.reshape(pd.read_csv('./data/task1_13_learn_y.csv').values, -1))\n",
    "\n",
    "#X_test = convert_bad_data(pd.read_csv('./data/task1_13_test_X.csv').values)\n",
    "\n",
    "X_train = pd.read_csv('./data/task1_13_learn_X.csv', header=None, sep=' ').values\n",
    "y_train = np.reshape(np.int64(pd.read_csv('./data/task1_13_learn_y.csv',header=None, sep=' ').values), -1)\n",
    "\n",
    "X_test = pd.read_csv('./data/task1_13_test_X.csv',header=None, sep=' ').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000,), (10000, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 in train: 834 \n",
      " 1 in train: 166\n"
     ]
    }
   ],
   "source": [
    "print(\"0 in train:\", X_train[y_train==0].shape[0], '\\n', \"1 in train:\", X_train[y_train==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = X_train#StandardScaler(with_mean=False).fit_transform(X_train)\n",
    "\n",
    "#df.apply(average)\n",
    "#df.apply(max) - df.apply(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized = pd.DataFrame(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,8))\n",
    "# sns.heatmap(df_normalized.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_normalized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_features = df_normalized[[0, 2, 4, 6, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,8))\n",
    "# sns.heatmap(df_selected_features.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_selected_features, (pd.DataFrame(y_train)).rename(columns={0: 10})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleted_parameters = check_outliers(pd.DataFrame(X_train))\n",
    "# X_train_ = np.delete(X_train, Deleted_parameters, axis = 0)\n",
    "# y_train = np.delete(y_train, Deleted_parameters, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(pd.concat([df_normalized, pd.DataFrame(y_train)], axis=1, ignore_index=True), hue=10)\n",
    "# sns.pairplot(df, hue=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 2, 4, 6, 8, 9, 10], dtype='int64')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _=plt.hist(X_scaled[np.where(y_train==1)][:,1], bins=20, color=(1,0,0,0.5))\n",
    "# _=plt.hist(X_scaled[np.where(y_train==0)][:,1], bins=20, color=(0,0,1,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X_scaled[np.where(y_train==1)].mean(0))\n",
    "# plt.plot(X_scaled[np.where(y_train==0)].mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ = svm.OneClassSVM(gamma=10, nu=0.1)\n",
    "#data = pandas.read_csv(\"train.csv\", na_values=\"NaN\")\n",
    "sdata = shuffle(df, random_state=321)\n",
    "\n",
    "svm_.fit(sdata)\n",
    "labels = svm_.predict(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40000000000000002"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels==1).mean() # -- не выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 7) (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(sdata.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df[labels==1], hue=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values = sdata.values\n",
    "norm_obj = [i for i in range(labels.shape[0]) if labels[i]==1] # Номера объектов, не являющихся выбросами\n",
    "# anomaly_obj = [i for i in range(labels.shape[0]) if labels[i]==-1] # Номера шумовых объектов\n",
    "# n_features = sdata.shape[1] - 1\n",
    "# features = sdata.columns.values[:-1]\n",
    "# x = y = 0\n",
    "\n",
    "# fig, axes = plt.subplots(2, 3, figsize = (12,8))\n",
    "# for i in range(n_features):\n",
    "#     for j in range(i+1, n_features):\n",
    "#         axes[x, y%3].scatter(values[anomaly_obj, i], values[anomaly_obj, j], c=\"red\")\n",
    "#         axes[x, y%3].scatter(values[norm_obj, i], values[norm_obj, j], c=\"blue\")\n",
    "#         axes[x, y%3].set_xlabel(features[i])\n",
    "#         axes[x, y%3].set_ylabel(features[j])\n",
    "#         y += 1\n",
    "#     if i == 0:\n",
    "#         x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values = sdata.values\n",
    "norm_obj = [i for i in range(labels.shape[0]) if labels[i]==1] # Номера объектов, не являющихся выбросами\n",
    "# anomaly_obj = [i for i in range(labels.shape[0]) if labels[i]==-1] # Номера шумовых объектов\n",
    "# n_features = sdata.shape[1] - 1\n",
    "# features = sdata.columns.values[:-1]\n",
    "# x = y = 0\n",
    "\n",
    "# fig, axes = plt.subplots(2, 3, figsize = (12,8))\n",
    "# for i in range(n_features):\n",
    "#     for j in range(i+1, n_features):\n",
    "#         axes[x, y%3].scatter(values[anomaly_obj, i], values[anomaly_obj, j], c=\"red\")\n",
    "#         axes[x, y%3].scatter(values[norm_obj, i], values[norm_obj, j], c=\"blue\")\n",
    "#         axes[x, y%3].set_xlabel(features[i])\n",
    "#         axes[x, y%3].set_ylabel(features[j])\n",
    "#         y += 1\n",
    "#     if i == 0:\n",
    "#         x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_filtered_df = df[labels==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 in train: 335 \n",
      " 1 in train: 65\n"
     ]
    }
   ],
   "source": [
    "print(\"0 in train:\", svm_filtered_df[svm_filtered_df[10]==0].shape[0], '\\n', \"1 in train:\", svm_filtered_df[svm_filtered_df[10]==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(X, alpha):\n",
    "    num_features = X.shape[1]\n",
    "    q_low = X.quantile(alpha, axis=0)\n",
    "    q_up = X.quantile(1 - alpha, axis=0)\n",
    "    X_new = X.values.copy()\n",
    "    print(num_features, X.shape[0])\n",
    "    \n",
    "    for i in range(num_features):\n",
    "        median = X[i].median()\n",
    "    for j in range(X.shape[0]):\n",
    "        if X_new[j][i] < q_low[i] or X_new[j][i] > q_up[i]:\n",
    "            X_new[j][i] = median\n",
    "            \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 1.0\n",
      "AUC 1.0\n",
      "NUM 0\n",
      "ASY1 -3350\n",
      "ASY2 -400\n"
     ]
    }
   ],
   "source": [
    "#rho = 0.9\n",
    "#Predict = cross_val_predict(estimator=naive_bayes.GaussianNB(priors=[rho,1-rho]), X=X_train_new, y=y_train_new, cv = 10, method='predict_proba')\n",
    "Predict = cross_val_predict(estimator=LogisticRegression(penalty = 'l1'), X=svm_filtered_df.values, y=y_train[norm_obj], cv = 10, method='predict_proba')\n",
    "\n",
    "print('ACC', metrics.accuracy_score(y_train[norm_obj], np.argmax(Predict, axis = 1)))\n",
    "print('AUC', metrics.roc_auc_score(y_train[norm_obj], Predict[:,1]))\n",
    "print('NUM', _num(y_train[norm_obj], np.argmax(Predict, axis = 1)))\n",
    "print('ASY1', _asy1(y_train[norm_obj], np.argmax(Predict, axis = 1)))\n",
    "print('ASY2', _asy2(y_train[norm_obj], np.argmax(Predict, axis = 1)))\n",
    "\n",
    "#Predict_For_ASY1 = naive_bayes.GaussianNB(priors=[rho,1-rho]).fit(X_train, y_train).predict(X_test)\n",
    "#Predict_For_ASY1 = naive_bayes.GaussianNB(priors=[rho,1-rho]).fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_predict(estimator=LogisticRegression(penalty = 'l1'), X=svm_filtered_df.values, y=y_train[norm_obj], cv = 10, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
